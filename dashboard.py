# dashboard_review.py
import os
import math
import numpy as np
import pandas as pd
import altair as alt
import streamlit as st

st.set_page_config(page_title="HFTSim â€“ Industrial Review", layout="wide")
st.title("ğŸ¦ HFTSim â€“ Strategy Review Dashboard")

# -------------------------------
# 1) æ–‡ä»¶è·¯å¾„
# -------------------------------
SIGNAL_FILE = "data/signals_buy.csv"          # timestamp,price,signal(0/1/2)
TRADE_FILE  = "data/trades_executed.csv"      # ts_ns,side,price,qty,buy_id,sell_id

# -------------------------------
# 2) è¯»æ•°æ® + é¢„å¤„ç†
# -------------------------------
@st.cache_data(show_spinner=False)
def load_signals(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        return pd.DataFrame(columns=["timestamp","price","signal"])
    df = pd.read_csv(path)
    # å…è®¸ ns æ—¶é—´æˆ³æˆ–æ ‡å‡†æ—¶é—´å­—ç¬¦ä¸²
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
    # è¿‡æ»¤åæ—¶é—´
    df = df[df["timestamp"].notna()].sort_values("timestamp")
    # æ˜ å°„ä¿¡å·æ–‡æœ¬ï¼ˆéå¿…éœ€ï¼Œä»…å¤‡ç”¨ï¼‰
    mapping = {0:"BUY", 1:"SELL", 2:"HOLD"}
    if "signal" in df.columns:
        df["signal_txt"] = df["signal"].map(mapping).fillna(df["signal"].astype(str))
    else:
        df["signal_txt"] = "NA"
    # å»é‡
    df = df.drop_duplicates(subset=["timestamp"])
    return df.reset_index(drop=True)

@st.cache_data(show_spinner=False)
def load_trades(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        cols = ["ts_ns","side","price","qty","buy_id","sell_id"]
        return pd.DataFrame(columns=cols)
    df = pd.read_csv(path)
    # æˆäº¤æ—¶é—´å¯èƒ½æ˜¯ ns æ—¶é—´æˆ³æˆ–å­—ç¬¦ä¸²
    # å¦‚æœæ˜¯å¤§æ•´æ•°ï¼Œpd.to_datetimeå¯ä»¥è¯†åˆ« nsï¼›è‹¥å¤±è´¥ï¼Œerrors='coerce'
    df["ts_ns"] = pd.to_datetime(df["ts_ns"], errors="coerce")
    df = df[df["ts_ns"].notna()].sort_values("ts_ns")
    # æ–¹å‘è§„èŒƒåŒ–
    if "side" in df.columns:
        df["side"] = df["side"].str.upper().str.strip()
    else:
        df["side"] = "UNKNOWN"
    # æ•°å€¼
    for c in ["price","qty"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    df = df.dropna(subset=["price","qty"])
    return df.reset_index(drop=True)

df_sig  = load_signals(SIGNAL_FILE)
df_trd  = load_trades(TRADE_FILE)

if df_trd.empty:
    st.warning("æ²¡æœ‰å‘ç°æˆäº¤æ•°æ®ï¼ˆdata/trades_executed.csvï¼‰ã€‚å…ˆè·‘å®Œæ¨¡æ‹Ÿå†æ¥å¤ç›˜ã€‚")
    st.stop()

# -------------------------------
# 3) è‡ªåŠ¨é€‰æ‹©èšåˆç²’åº¦ + æ§ä»¶
# -------------------------------
t0 = df_trd["ts_ns"].min()
t1 = df_trd["ts_ns"].max()
span_sec = (t1 - t0).total_seconds() if pd.notna(t0) and pd.notna(t1) else 0.0

# æŒ‰è·¨åº¦è‡ªåŠ¨ç»™ä¸€ä¸ªåˆç†ç²’åº¦
def auto_bucket(seconds: float) -> str:
    if seconds <= 2.0:
        return "10ms"
    if seconds <= 60.0:
        return "100ms"
    if seconds <= 3600.0:
        return "1s"
    return "1min"

default_bucket = auto_bucket(span_sec)
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    st.write(f"æ•°æ®è·¨åº¦çº¦ï¼š**{span_sec:.3f} ç§’**")
    bucket = st.selectbox("èšåˆç²’åº¦", ["10ms","100ms","1s","1min"], index=["10ms","100ms","1s","1min"].index(default_bucket))
    show_tables = st.checkbox("æ˜¾ç¤ºæ˜ç»†è¡¨ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰", value=False)

# -------------------------------
# 4) æ ‡çš„ä»·æ ¼åŸºå‡†ï¼ˆç”¨äºæŒä»“ä¼°å€¼/æ»‘ç‚¹å‚è€ƒï¼‰
#    ç”¨ signals çš„ price ä½œä¸º midï¼ˆä¸å®Œç¾ï¼Œä½†å¤Ÿå¤ç›˜ï¼‰
# -------------------------------
if df_sig.empty:
    # ä¸‡ä¸€æ²¡æœ‰signalsï¼Œç”¨æˆäº¤åŠ æƒå‡ä»·ä»£ç†ä»·æ ¼æ—¶é—´çº¿
    ref = df_trd[["ts_ns","price","qty"]].copy()
    ref = ref.rename(columns={"ts_ns":"ts"})
    # ä»¥æˆäº¤æ—¶é—´ä¸ºé”šç‚¹æ„é€ ä»·æ ¼æ›²çº¿
    ref = ref.set_index("ts").groupby(pd.Grouper(freq=bucket)).apply(lambda x: np.average(x["price"], weights=x["qty"]) if x["qty"].sum()>0 else x["price"].mean()).to_frame("mid")
else:
    ref = df_sig[["timestamp","price"]].rename(columns={"timestamp":"ts","price":"mid"}).copy()
    ref = ref.set_index("ts").sort_index()
    # å…ˆæŒ‰è¾ƒç»†é¢‘ç‡é‡é‡‡æ ·å†å‰å‘å¡«å……
    ref = ref.resample(bucket).last().ffill()

ref = ref.reset_index().rename(columns={"index":"ts"})
ref = ref.dropna(subset=["ts","mid"])

# -------------------------------
# 5) æ„å»ºæŒä»“ä¸PnLï¼ˆä»“ä½æ³•ï¼šç°é‡‘+æŒä»“*midï¼‰
# -------------------------------
# å°†æˆäº¤æŒ‰èšåˆç²’åº¦å¯¹é½
trd = df_trd.copy()
trd["bucket_ts"] = trd["ts_ns"].dt.floor(bucket)

# æ–¹å‘ï¼šBUY æ­£ï¼ŒSELL è´Ÿ
trd["signed_qty"] = np.where(trd["side"]=="BUY", trd["qty"], np.where(trd["side"]=="SELL", -trd["qty"], 0))
trd["cash_flow"]  = - trd["price"] * trd["signed_qty"]   # ä¹°å…¥ç°é‡‘æµä¸ºè´Ÿï¼Œå–å‡ºä¸ºæ­£

# èšåˆï¼ˆæ¯ä¸ªæ—¶é—´æ¡¶ï¼‰
agg = trd.groupby("bucket_ts").agg(
    net_qty=("signed_qty","sum"),
    cash_delta=("cash_flow","sum"),
    vol=("qty","sum"),
    avg_price=("price","mean"),
).reset_index().rename(columns={"bucket_ts":"ts"})

# å’Œå‚è€ƒä»·æ ¼æ—¶é—´çº¿åˆå¹¶
timeline = pd.merge(ref, agg, on="ts", how="outer").sort_values("ts")
timeline[["net_qty","cash_delta","vol","avg_price"]] = timeline[["net_qty","cash_delta","vol","avg_price"]].fillna(0)

# é€’æ¨ï¼šæŒä»“ & ç°é‡‘ & è´¦æˆ·å‡€å€¼
timeline["position"] = timeline["net_qty"].cumsum()
timeline["cash"]     = timeline["cash_delta"].cumsum()
timeline["equity"]   = timeline["cash"] + timeline["position"] * timeline["mid"]

# per-bucketæ”¶ç›Šï¼ˆÎ”equityï¼‰
timeline["pnl_step"] = timeline["equity"].diff().fillna(0)
timeline["cum_pnl"]  = timeline["equity"] - timeline["equity"].iloc[0]

# -------------------------------
# 6) å…³é”®æŒ‡æ ‡
# -------------------------------
def max_drawdown(series: pd.Series) -> float:
    if series.empty:
        return 0.0
    peak = series.cummax()
    dd = (series - peak)
    return dd.min()

def sharpe_from_steps(steps: pd.Series, seconds_per_bucket: float) -> float:
    # ç®€åŒ–è®¡ç®—ï¼šSharpe = mean(step)/std(step) * sqrt(å¹´åŒ–æ­¥æ•°)
    # å¹´åŒ–ç³»æ•°ï¼šä¸€å¹´ç§’æ•°çº¦ 31_536_000
    if steps.std(ddof=1) == 0:
        return 0.0
    ann_factor = math.sqrt(31_536_000 / seconds_per_bucket) if seconds_per_bucket>0 else 0
    return steps.mean() / steps.std(ddof=1) * ann_factor

# ä¼°è®¡æ¯ä¸ªbucketçš„ç§’æ•°
bucket_sec = {"10ms":0.01, "100ms":0.1, "1s":1.0, "1min":60.0}[bucket]

final_pnl   = float(timeline["cum_pnl"].iloc[-1]) if len(timeline)>0 else 0.0
mdd         = float(max_drawdown(timeline["cum_pnl"]))
sharpe      = float(sharpe_from_steps(timeline["pnl_step"], bucket_sec))
turnover    = float(trd["qty"].sum() / (timeline["position"].abs().mean() + 1e-9))  # ç²—ç•¥æ¢æ‰‹ç‡
hit_rate    = float((timeline["pnl_step"]>0).mean()) if len(timeline)>0 else 0.0

# æ»‘ç‚¹ä¼°è®¡ï¼šæˆäº¤ä»· vs åŒæ¡¶å‚è€ƒä»·
# å°†æˆäº¤ä¸ ref æŒ‰æœ€è¿‘æ¡¶å¯¹é½ï¼Œè®¡ç®— (trade_price - mid) * side_sign
slip = pd.merge(
    trd[["ts_ns","bucket_ts","side","price","qty","signed_qty"]],
    ref.rename(columns={"ts":"bucket_ts"}),
    on="bucket_ts", how="left"
)
slip["side_sign"] = np.where(slip["signed_qty"]>=0, 1, -1)  # BUYæ­£ SELLè´Ÿ
slip["slippage"]  = (slip["price"] - slip["mid"]) * slip["side_sign"]

avg_slip   = float((slip["slippage"]).mean()) if not slip.empty else 0.0
med_slip   = float((slip["slippage"]).median()) if not slip.empty else 0.0

# -------------------------------
# 7) å¸ƒå±€ä¸å¯è§†åŒ–
# -------------------------------
col1, col2 = st.columns([2,1])

with col1:
    st.subheader("ç´¯è®¡ PnLï¼ˆèšåˆåï¼‰")
    if not timeline.empty:
        chart_pnl = alt.Chart(timeline).mark_line().encode(
            x=alt.X("ts:T", title="Time"),
            y=alt.Y("cum_pnl:Q", title="Cumulative PnL"),
            tooltip=["ts:T","cum_pnl:Q","position:Q","mid:Q"]
        ).interactive()
        st.altair_chart(chart_pnl, use_container_width=True)
    else:
        st.info("æ—¶é—´çº¿ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶ã€‚")

with col2:
    st.subheader("å…³é”®æŒ‡æ ‡")
    st.metric("Final PnL", f"{final_pnl:,.2f}")
    st.metric("Max Drawdown", f"{mdd:,.2f}")
    st.metric("Sharpe (approx.)", f"{sharpe:,.2f}")
    st.metric("Hit Rate", f"{hit_rate*100:.1f}%")
    st.metric("Turnover (rough)", f"{turnover:.2f}")
    st.metric("Avg Slippage", f"{avg_slip:.6f}")
    st.metric("Median Slippage", f"{med_slip:.6f}")

st.subheader("æˆäº¤é‡éšæ—¶é—´ï¼ˆèšåˆï¼‰")
if not timeline.empty:
    vol_bar = alt.Chart(timeline).mark_bar().encode(
        x=alt.X("ts:T", title="Time"),
        y=alt.Y("vol:Q", title="Volume"),
        tooltip=["ts:T","vol:Q","avg_price:Q"]
    )
    st.altair_chart(vol_bar, use_container_width=True)
else:
    st.info("æ— æ•°æ®ç»˜åˆ¶æˆäº¤é‡ã€‚")

st.subheader("å‡€æ•å£ / æŒä»“ï¼ˆèšåˆï¼‰")
if not timeline.empty:
    pos_chart = alt.Chart(timeline).mark_line(color="orange").encode(
        x="ts:T", y=alt.Y("position:Q", title="Position"),
        tooltip=["ts:T","position:Q"]
    ).interactive()
    st.altair_chart(pos_chart, use_container_width=True)

st.subheader("æ»‘ç‚¹åˆ†å¸ƒï¼ˆæ–¹å‘è°ƒæ•´åï¼‰")
if not slip.empty:
    slip_hist = alt.Chart(slip.dropna(subset=["slippage"])).mark_bar().encode(
        x=alt.X("slippage:Q", bin=alt.Bin(maxbins=50), title="Slippage per trade (signed)"),
        y="count()"
    )
    st.altair_chart(slip_hist, use_container_width=True)
else:
    st.info("æœªèƒ½è®¡ç®—æ»‘ç‚¹åˆ†å¸ƒã€‚")

if show_tables:
    st.divider()
    st.subheader("æ˜ç»†ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰")
    st.write("Timelineï¼ˆèšåˆåï¼‰")
    st.dataframe(timeline.tail(200))
    st.write("Tradesï¼ˆåŸå§‹ï¼‰")
    st.dataframe(df_trd.tail(200))
    if not df_sig.empty:
        st.write("Signalsï¼ˆåŸå§‹ï¼‰")
        st.dataframe(df_sig.tail(200))
